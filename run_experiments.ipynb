{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0f23faf4bfe871c203c8bec80520af5927fc7cb1ae3bd834ddf554ee587ad1c05",
   "display_name": "Python 3.8.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x6733f50>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from experiments.train_experiments import train_experiments\n",
    "from experiments.utils import *\n",
    "from agent.agents import *\n",
    "from agent.switching_agents import *\n",
    "from environments.env import * \n",
    "from definitions import ROOT_DIR\n",
    "\n",
    "from torch.optim import RMSprop\n",
    "import numpy as np\n",
    "import random \n",
    "import torch\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "np.random.seed(12345678)\n",
    "random.seed(12345678)\n",
    "torch.manual_seed(12345678)\n"
   ]
  },
  {
   "source": [
    "## Train baselines and 2-stage algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# configure environment\n",
    "env_generator = Environment()\n",
    "width = 3\n",
    "height = 20\n",
    "depth = height//3\n",
    "init_traffic_level = 'light'\n",
    "env_params = {'width' : width, 'height':height, 'init_traffic_level': init_traffic_level, 'depth': depth}\n",
    "env_generator_fn = lambda:env_generator.generate_grid_world(**env_params)\n",
    "\n",
    "n_traj = 20000\n",
    "n_episodes = 20000\n",
    "\n",
    "# Human agent\n",
    "estimation_noise = 2.0\n",
    "switching_noise = 2.0\n",
    "human  = NoisyDriverAgent(env_generator, noise_sd=estimation_noise, noise_sw=switching_noise, c_H=0.0)\n",
    "\n",
    "# Configure switching and machine agents\n",
    "\n",
    "# define state size \n",
    "n_state_features_strings = 1 + depth*(width + 1)\n",
    "\n",
    "# define state size in 1-hot encoding\n",
    "n_cell_types = len(env_generator.cell_types)\n",
    "n_traffic_levels = len(env_generator.traffic_levels)\n",
    "n_state_features_1hot =  n_cell_types + depth*( n_traffic_levels + 1 + width*(n_cell_types + 1)) \n",
    "\n",
    "n_state_features = (n_state_features_strings, n_state_features_1hot)\n",
    "\n",
    "n_actions = 3\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer_fn = lambda params: RMSprop(params, lr)\n",
    "\n",
    "machine = MachineDriverAgent(n_state_features, n_actions, optimizer_fn, c_M=0.2)\n",
    "fully_automated = FixedSwitchingMachine(n_state_features, optimizer_fn)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'{ROOT_DIR}/outputs/human_{estimation_noise}_{switching_noise}_{init_traffic_level}_trajectories_{n_traj}', 'rb') as file:\n",
    "    trajectories = pickle.load(file)\n",
    "with open(f'{ROOT_DIR}/outputs/human_{estimation_noise}_{switching_noise}_{init_traffic_level}_trajectories_{n_traj}_agent', 'rb') as file:\n",
    "    human = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19999\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# gather human trajectories\n",
    "trajectories = gather_human_trajectories(human, env_generator, n_traj,**env_params)\n",
    "# save for later\n",
    "with open(f'{ROOT_DIR}/outputs/human_{estimation_noise}_{switching_noise}_{init_traffic_level}_trajectories_{n_traj}', 'wb') as file:\n",
    "    pickle.dump(trajectories, file, pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'{ROOT_DIR}/outputs/human_{estimation_noise}_{switching_noise}_{init_traffic_level}_trajectories_{n_traj}_agent', 'wb') as file:\n",
    "    pickle.dump(human, file, pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_fixed_policies = SwitchingAgent(n_state_features, optimizer_fn, c_M=0.2, c_H=0.0, eps=0.1)\n",
    "# same initialisation\n",
    "switch_full = deepcopy(switch_fixed_policies)\n",
    "# must be deepcopy of machine before training\n",
    "switch_machine = deepcopy(machine)\n",
    "\n",
    "algos_to_train = {'fixed_policies': (switch_fixed_policies,[human, machine]), 'switching':( switch_full,[human, switch_machine]) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_a = deepcopy(fully_automated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "algos = {'pre_trained_machine': (fully_automated, [human, machine])}\n",
    "algos, fully_automated_costs = train_experiments(algos, trajectories[:1000], env_generator_fn, 0)\n",
    "machine.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-17 20:45:13.320152, Episode 1000, Fully automated on-policy algorithm cumulative cost: 35535.8\n",
      "2021-05-17 20:47:13.406020, Episode 2000, Fully automated on-policy algorithm cumulative cost: 72123.8\n",
      "2021-05-17 20:49:16.207044, Episode 3000, Fully automated on-policy algorithm cumulative cost: 109591.80000000002\n",
      "2021-05-17 20:51:19.102073, Episode 4000, Fully automated on-policy algorithm cumulative cost: 147059.8\n",
      "Wall time: 29min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fully_automated, [human, machine] , fully_automated_costs = run_pre_train_machine(fully_automated, [human, machine], trajectories, env_generator_fn, n_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "41.80000000000002 63.80000000000001\n"
     ]
    }
   ],
   "source": [
    "from plot.plot_path import PlotPath\n",
    "from experiments.utils import *\n",
    "gird_world = env_generator_fn()\n",
    "plt_path = PlotPath(gird_world, n_try=1)\n",
    "plt_path1 = PlotPath(gird_world, n_try=1)\n",
    "\n",
    "\n",
    "\n",
    "cost = learn_evaluate(fully_automated, [human, machine] ,gird_world , \n",
    "is_learn=False, plt_path = plt_path, machine_only=True)\n",
    "\n",
    "cost1 = learn_evaluate(f_a, [human,  switch_machine] ,gird_world ,\n",
    "is_learn=False, plt_path = plt_path1)\n",
    "\n",
    "plt_path.plot('../machine_only_light.png')\n",
    "plt_path1.plot('../machine_dummy_only_light.png')\n",
    "\n",
    "print(cost, cost1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'add_line'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-23c71eb0845a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mgird_world\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_generator_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         cost = learn_evaluate(fully_automated, [human, machine] ,gird_world , \n\u001b[0m\u001b[0;32m      7\u001b[0m         is_learn=False, plt_path = None, machine_only=True)\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\Project_SWS\\code\\experiments-source-code\\human-machine-switching\\experiments\\utils.py\u001b[0m in \u001b[0;36mlearn_evaluate\u001b[1;34m(switching_agent, acting_agents, env, is_learn, ret_trajectory, n_try, plt_path, machine_only)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhuman_cf_costs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhuman_cf_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mplt_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHUMAN_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret_trajectory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'add_line'"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for _ in range(10):\n",
    "    is_better = 0\n",
    "    for i in range(100):\n",
    "        gird_world = env_generator_fn()\n",
    "        cost = learn_evaluate(fully_automated, [human, machine] ,gird_world , \n",
    "        is_learn=False, plt_path = plt_path, machine_only=True)\n",
    "\n",
    "        cost1 = learn_evaluate(f_a, [human,  switch_machine] ,gird_world , \n",
    "        is_learn=False, plt_path = plt_path1)\n",
    "\n",
    "        is_better+= (cost1 >= cost)\n",
    "\n",
    "    print(is_better/100)\n",
    "    res.append(is_better/100)\n",
    "    print(cost, cost1)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "source": [
    "10000 off 15000 on\n",
    "0.56\n",
    "0.46\n",
    "0.47\n",
    "0.55\n",
    "0.52\n",
    "0.55\n",
    "0.51\n",
    "0.44\n",
    "0.57\n",
    "0.6\n",
    "0.523"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import torch\n",
    "a = MachineDriverAgent(n_state_features, n_actions, optimizer_fn, c_M=0.2)\n",
    "b = deepcopy(a)\n",
    "torch.all(list(switch_machine.network.parameters())[0] == list(machine.network.parameters())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([4.2675e-14, 0.0000e+00, 2.3021e-14])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "(list(machine.network.parameters())[3]).grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0031,  0.0362, -0.0103], requires_grad=True))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "list(switch_machine.network.parameters())[3],list(machine.network.parameters())[3]"
   ]
  }
 ]
}