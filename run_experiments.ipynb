{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0f23faf4bfe871c203c8bec80520af5927fc7cb1ae3bd834ddf554ee587ad1c05",
   "display_name": "Python 3.8.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x6373f10>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from experiments.pre_train_machine_policy import run_pre_train_machine\n",
    "from experiments.utils import *\n",
    "from agent.agents import *\n",
    "from agent.switching_agents import *\n",
    "from environments.env import * \n",
    "from definitions import ROOT_DIR\n",
    "\n",
    "from torch.optim import RMSprop\n",
    "import numpy as np\n",
    "import random \n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "np.random.seed(12345678)\n",
    "random.seed(12345678)\n",
    "torch.manual_seed(12345678)\n"
   ]
  },
  {
   "source": [
    "## Train baselines and 2-stage algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9999\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "env_generator = Environment()\n",
    "width = 3\n",
    "height = 20\n",
    "depth = height//3\n",
    "init_traffic_level = 'light'\n",
    "env_params = {'width' : width, 'height':height, 'init_traffic_level': init_traffic_level, 'depth': depth}\n",
    "env_generator_fn = lambda:env_generator.generate_grid_world(**env_params)\n",
    "\n",
    "n_traj = 10000\n",
    "n_episodes = 5000\n",
    "\n",
    "estimation_noise = 2.0\n",
    "switching_noise = 2.0\n",
    "human  = NoisyDriverAgent(env_generator, noise_sd=estimation_noise, noise_sw=switching_noise, c_H=0.0)\n",
    "# gather human trajectories\n",
    "trajectories = gather_human_trajectories(human, env_generator, n_traj,**env_params)\n",
    "\n",
    "\n",
    "# define state size \n",
    "n_state_features_strings = 1 + depth*(width + 1)\n",
    "\n",
    "# define state size in 1-hot encoding\n",
    "n_cell_types = len(env_generator.cell_types)\n",
    "n_traffic_levels = len(env_generator.traffic_levels)\n",
    "n_state_features_1hot =  n_cell_types + depth*( n_traffic_levels + 1 + width*(n_cell_types + 1)) \n",
    "\n",
    "n_state_features = (n_state_features_strings, n_state_features_1hot)\n",
    "\n",
    "n_actions = 3\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer_fn = lambda params: RMSprop(params, lr)\n",
    "\n",
    "machine = MachineDriverAgent(n_state_features, n_actions, optimizer_fn, c_M=0.2)\n",
    "fully_automated = FixedSwitchingMachine(n_state_features, optimizer_fn)\n",
    "\n",
    "\n",
    "\n",
    "with open(f'{ROOT_DIR}/outputs/human_{estimation_noise}_{switching_noise}_{init_traffic_level}_trajectories_{n_traj}', 'wb') as file:\n",
    "    pickle.dump(trajectories, file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-17 20:45:13.320152, Episode 1000, Fully automated on-policy algorithm cumulative cost: 35535.8\n",
      "2021-05-17 20:47:13.406020, Episode 2000, Fully automated on-policy algorithm cumulative cost: 72123.8\n",
      "2021-05-17 20:49:16.207044, Episode 3000, Fully automated on-policy algorithm cumulative cost: 109591.80000000002\n",
      "2021-05-17 20:51:19.102073, Episode 4000, Fully automated on-policy algorithm cumulative cost: 147059.8\n",
      "Wall time: 29min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fully_automated, [human, machine] , fully_automated_costs = run_pre_train_machine(fully_automated, [human, machine], trajectories, env_generator_fn, n_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-17 22:38:36.704283, Episode 1000, Fully automated on-policy algorithm cumulative cost: 38895.8\n",
      "2021-05-17 22:40:36.331125, Episode 2000, Fully automated on-policy algorithm cumulative cost: 77009.8\n",
      "2021-05-17 22:42:36.204982, Episode 3000, Fully automated on-policy algorithm cumulative cost: 115533.80000000002\n",
      "2021-05-17 22:44:37.588925, Episode 4000, Fully automated on-policy algorithm cumulative cost: 153841.8\n",
      "Wall time: 10min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# run for more 5000 on policy\n",
    "fully_automated.trainable = True\n",
    "machine.trainable = True\n",
    "fully_automated, [human, machine] , fully_automated_costs = run_pre_train_machine(fully_automated, [human, machine], [], env_generator_fn, n_episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "49.800000000000026 79.80000000000004\n"
     ]
    }
   ],
   "source": [
    "from plot.plot_path import PlotPath\n",
    "from experiments.utils import *\n",
    "gird_world = env_generator_fn()\n",
    "plt_path = PlotPath(gird_world, n_try=1)\n",
    "plt_path1 = PlotPath(gird_world, n_try=1)\n",
    "\n",
    "\n",
    "\n",
    "cost = learn_evaluate(fully_automated, [human, machine] ,gird_world , \n",
    "is_learn=False, plt_path = plt_path)\n",
    "\n",
    "cost1 = learn_evaluate(fully_automated, [human,  MachineDriverAgent(n_state_features, n_actions, optimizer_fn, c_M=0.2)] ,gird_world , \n",
    "is_learn=False, plt_path = plt_path1)\n",
    "\n",
    "plt_path.plot('../machine_only_light.png')\n",
    "plt_path1.plot('../machine_dummy_only_light.png')\n",
    "\n",
    "print(cost, cost1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.51\n",
      "0.44\n",
      "0.44\n",
      "0.46\n",
      "0.46\n",
      "0.46\n",
      "0.39\n",
      "0.49\n",
      "0.5\n",
      "0.48\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    is_better = 0\n",
    "    for i in range(100):\n",
    "        gird_world = env_generator_fn()\n",
    "        cost = learn_evaluate(fully_automated, [human, machine] ,gird_world , \n",
    "        is_learn=False, plt_path = None)\n",
    "\n",
    "        cost1 = learn_evaluate(fully_automated, [human,  MachineDriverAgent(n_state_features, n_actions, optimizer_fn, c_M=0.2)] ,gird_world , \n",
    "        is_learn=False, plt_path = None)\n",
    "\n",
    "        is_better+= (cost1 >= cost)\n",
    "\n",
    "    print(is_better/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.56\n",
      "0.46\n",
      "0.47\n",
      "0.55\n",
      "0.52\n",
      "0.55\n",
      "0.51\n",
      "0.44\n",
      "0.57\n",
      "0.6\n",
      "0.523\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for _ in range(10):\n",
    "    is_better = 0\n",
    "    for i in range(100):\n",
    "        gird_world = env_generator_fn()\n",
    "        cost = learn_evaluate(fully_automated, [human, machine] ,gird_world , \n",
    "        is_learn=False, plt_path = None)\n",
    "\n",
    "        cost1 = learn_evaluate(fully_automated, [human,  MachineDriverAgent(n_state_features, n_actions, optimizer_fn, c_M=0.2)] ,gird_world , \n",
    "        is_learn=False, plt_path = None)\n",
    "\n",
    "        is_better+= (cost1 >= cost)\n",
    "\n",
    "    print(is_better/100)\n",
    "    res.append(is_better/100)\n",
    "print(np.mean(res))"
   ]
  }
 ]
}